{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akn13ehVc2yQ"
      },
      "source": [
        "# Super-Resolution Exercises\n",
        "\n",
        "## Comparison of basic Super-resolution methods for SAR Ship classification\n",
        "\n",
        "**Objective:** Implement and compare basic upsampling techniques using opencv.\n",
        "\n",
        "**Tasks:**\n",
        "1. Loading the dataset.\n",
        "2. Downsampling each image.\n",
        "3. Apply various upsampling techniques.\n",
        "4. Comparing the scores and writing average scores.\n",
        "5. Upscaling the images and storing them in a new folder for cnn's."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YHBna_mdjIB"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torchsr\n",
            "  Downloading torchsr-1.0.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /home/si-lab/.local/lib/python3.10/site-packages (from torchsr) (2.0.1)\n",
            "Requirement already satisfied: torchvision>=0.6 in /home/si-lab/.local/lib/python3.10/site-packages (from torchsr) (0.15.2)\n",
            "Requirement already satisfied: filelock in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (4.11.0)\n",
            "Requirement already satisfied: sympy in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (1.12)\n",
            "Requirement already satisfied: networkx in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/si-lab/.local/lib/python3.10/site-packages (from torch>=1.6->torchsr) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/si-lab/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->torchsr) (67.8.0)\n",
            "Requirement already satisfied: wheel in /home/si-lab/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->torchsr) (0.40.0)\n",
            "Requirement already satisfied: cmake in /home/si-lab/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6->torchsr) (3.26.3)\n",
            "Requirement already satisfied: lit in /home/si-lab/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6->torchsr) (16.0.5.post0)\n",
            "Requirement already satisfied: numpy in /home/si-lab/.local/lib/python3.10/site-packages (from torchvision>=0.6->torchsr) (1.24.1)\n",
            "Requirement already satisfied: requests in /home/si-lab/.local/lib/python3.10/site-packages (from torchvision>=0.6->torchsr) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/si-lab/.local/lib/python3.10/site-packages (from torchvision>=0.6->torchsr) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/si-lab/.local/lib/python3.10/site-packages (from jinja2->torch>=1.6->torchsr) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/si-lab/.local/lib/python3.10/site-packages (from requests->torchvision>=0.6->torchsr) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.6->torchsr) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/si-lab/.local/lib/python3.10/site-packages (from requests->torchvision>=0.6->torchsr) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/si-lab/.local/lib/python3.10/site-packages (from requests->torchvision>=0.6->torchsr) (2023.5.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/si-lab/.local/lib/python3.10/site-packages (from sympy->torch>=1.6->torchsr) (1.3.0)\n",
            "Downloading torchsr-1.0.4-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: torchsr\n",
            "Successfully installed torchsr-1.0.4\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install torchsr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XuzyCzUSdld8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "import numpy as np\n",
        "import torch\n",
        "# import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "# import cv2\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from torchsr.models import edsr, rcan, carn\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_P5_REGc2yT"
      },
      "source": [
        "**Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "wsbNafdec2yV",
        "outputId": "2c8f36a5-6f7e-4130-e42b-4aa3496e8629"
      },
      "outputs": [],
      "source": [
        "# def upsample(image, scale_factor, method):\n",
        "#     if   method == \"BILINEAR\": method_up = Image.BILINEAR\n",
        "#     elif method == \"BICUBIC\":  method_up = Image.BICUBIC\n",
        "#     elif method == \"NEAREST\":  method_up = Image.NEAREST\n",
        "#     elif method == \"LANCZOS\":  method_up = Image.LANCZOS\n",
        "#     else:\n",
        "#         print(method, \"not found, using bicubic\")\n",
        "#         method_up = Image.BICUBIC\n",
        "\n",
        "#     # Resize the image using bicubic interpolation\n",
        "#     return image.resize(\n",
        "#         (int(image.width * scale_factor), int(image.height * scale_factor)),\n",
        "#         method_up\n",
        "#     )\n",
        "\n",
        "# main_path = \"data/\"\n",
        "\n",
        "# polarizations = [\"vv\", \"vh\"]\n",
        "# classes = [\"Cargo\", \"Fishing\", \"Tanker\"]\n",
        "\n",
        "# scores = {}\n",
        "\n",
        "# for pol in polarizations:\n",
        "#     if pol not in scores:\n",
        "#         scores[pol] = {}\n",
        "#     for cl in classes:\n",
        "#         if cl not in scores[pol]:\n",
        "#             scores[pol][cl] = []\n",
        "#         p_path = main_path + pol + \"/\" + cl\n",
        "#         images_list = os.listdir(p_path)\n",
        "#         t_images = len(images_list)\n",
        "#         score_ssim_2x = [0, 0, 0, 0]\n",
        "#         score_psnr_2x = [0, 0, 0, 0]\n",
        "#         score_ssim_4x = [0, 0, 0, 0]\n",
        "#         score_psnr_4x = [0, 0, 0, 0]\n",
        "#         for i_image in images_list:\n",
        "#             image_path = os.path.join(p_path, i_image)\n",
        "\n",
        "#             image_hr = Image.open(image_path).convert('RGB')\n",
        "#             # Get the original dimensions\n",
        "#             original_width, original_height = image_hr.size\n",
        "\n",
        "#             # Reduce dimensions by a factor of 2\n",
        "#             new_width_2x = original_width // 2\n",
        "#             new_height_2x = original_height // 2\n",
        "\n",
        "#             image_lr_2 = image_hr.resize((new_width_2x, new_height_2x), Image.ANTIALIAS)\n",
        "#             # image_2x.save(\"image_reduced_by_2x.jpg\")  # Save the image resized by a factor of 2\n",
        "\n",
        "#             # Reduce dimensions by a factor of 4\n",
        "#             new_width_4x = original_width // 4\n",
        "#             new_height_4x = original_height // 4\n",
        "\n",
        "#             image_lr_4 = image_hr.resize((new_width_4x, new_height_4x), Image.ANTIALIAS)\n",
        "\n",
        "#             for idx, method in enumerate([\"NEAREST\", \"BILINEAR\", \"BICUBIC\", \"LANCZOS\"]):\n",
        "#                 image_up_2 = upsample(image_lr_2, scale_factor=2, method=method)\n",
        "#                 psnr_value_2 = psnr(np.array(image_hr), np.array(image_up_2))\n",
        "#                 score_psnr_2x[idx] += psnr_value_2\n",
        "#                 ssim_value_2 = ssim(np.array(image_hr), np.array(image_up_2), win_size=3, channel_axis=-1)\n",
        "#                 score_ssim_2x[idx] += ssim_value_2\n",
        "\n",
        "#                 image_up_4 = upsample(image_lr_4, scale_factor=4, method=method)\n",
        "#                 psnr_value_4 = np.round(psnr(np.array(image_hr), np.array(image_up_4)), 2)\n",
        "#                 score_psnr_4x[idx] += psnr_value_4\n",
        "#                 ssim_value_4 = np.round(ssim(np.array(image_hr), np.array(image_up_4), win_size=3, channel_axis=-1), 4)\n",
        "#                 score_ssim_4x[idx] += ssim_value_4\n",
        "        \n",
        "#         scores[pol][cl].append(list(numpy.array(score_ssim_2x)/t_images))\n",
        "#         scores[pol][cl].append(list(numpy.array(score_psnr_2x)/t_images))\n",
        "#         scores[pol][cl].append(list(numpy.array(score_ssim_4x)/t_images))\n",
        "#         scores[pol][cl].append(list(numpy.array(score_psnr_4x)/t_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upsample(image, target_size, method):\n",
        "    method_map = {\n",
        "        \"BILINEAR\": Image.BILINEAR,\n",
        "        \"BICUBIC\": Image.BICUBIC,\n",
        "        \"NEAREST\": Image.NEAREST,\n",
        "        \"LANCZOS\": Image.LANCZOS\n",
        "    }\n",
        "    method_up = method_map.get(method, Image.BICUBIC)\n",
        "    return image.resize(target_size, method_up)\n",
        "\n",
        "\n",
        "main_path = \"data/\"\n",
        "polarizations = [\"vv\", \"vh\"]\n",
        "classes = [\"Cargo\", \"Fishing\", \"Tanker\"]\n",
        "\n",
        "scores = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "for pol in polarizations:\n",
        "    print(pol)\n",
        "    for cl in classes:\n",
        "        print(cl)\n",
        "        p_path = os.path.join(main_path, pol, cl)\n",
        "        images_list = os.listdir(p_path)\n",
        "        t_images = len(images_list)\n",
        "\n",
        "        score_ssim_2x = [0, 0, 0, 0]\n",
        "        score_psnr_2x = [0, 0, 0, 0]\n",
        "        score_ssim_4x = [0, 0, 0, 0]\n",
        "        score_psnr_4x = [0, 0, 0, 0]\n",
        "\n",
        "        for i_image in images_list:\n",
        "            image_path = os.path.join(p_path, i_image)\n",
        "\n",
        "            try:\n",
        "                image_hr = Image.open(image_path).convert('RGB')\n",
        "            except Exception as e:\n",
        "                print(f\"Error opening image {image_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            original_width, original_height = image_hr.size\n",
        "            \n",
        "            if original_width < 2 or original_height < 2:\n",
        "                print(\"Image too small to downscale:\", image_path)\n",
        "                continue\n",
        "            image_lr_2 = image_hr.resize((original_width // 2, original_height // 2), Image.Resampling.LANCZOS)\n",
        "            image_lr_4 = image_hr.resize((original_width // 4, original_height // 4), Image.Resampling.LANCZOS)\n",
        "            image_hr_np = np.array(image_hr)\n",
        "\n",
        "            for idx, method in enumerate([\"NEAREST\", \"BILINEAR\", \"BICUBIC\", \"LANCZOS\"]):\n",
        "                # image_up_2 = upsample(image_lr_2, scale_factor=2, method=method)\n",
        "                image_up_2 = upsample(image_lr_2, (original_width, original_height), method=method)\n",
        "                image_up_2_np = np.array(image_up_2)\n",
        "\n",
        "                psnr_value_2 = np.round(psnr(image_hr_np, image_up_2_np), 2)\n",
        "                score_psnr_2x[idx] += psnr_value_2\n",
        "\n",
        "                ssim_value_2 = np.round(ssim(image_hr_np, image_up_2_np, win_size=3, channel_axis=-1), 4)\n",
        "                score_ssim_2x[idx] += ssim_value_2\n",
        "\n",
        "                # image_up_4 = upsample(image_lr_4, scale_factor=4, method=method)\n",
        "                image_up_4 = upsample(image_lr_4, (original_width, original_height), method=method)\n",
        "                image_up_4_np = np.array(image_up_4)\n",
        "\n",
        "                psnr_value_4 = np.round(psnr(image_hr_np, image_up_4_np), 2)\n",
        "                score_psnr_4x[idx] += psnr_value_4\n",
        "\n",
        "                ssim_value_4 = np.round(ssim(image_hr_np, image_up_4_np, win_size=3, channel_axis=-1), 4)\n",
        "                score_ssim_4x[idx] += ssim_value_4\n",
        "        \n",
        "        # Normalize the scores first to avoid redundant np.array() and division operations\n",
        "        ssim_2x_normalized = list(np.array(score_ssim_2x) / t_images)\n",
        "        psnr_2x_normalized = list(np.array(score_psnr_2x) / t_images)\n",
        "        ssim_4x_normalized = list(np.array(score_ssim_4x) / t_images)\n",
        "        psnr_4x_normalized = list(np.array(score_psnr_4x) / t_images)\n",
        "\n",
        "        # Assign the values to the respective dictionary keys\n",
        "        scores[pol][cl]['ssim_2x'] = ssim_2x_normalized\n",
        "        scores[pol][cl]['psnr_2x'] = psnr_2x_normalized\n",
        "        scores[pol][cl]['ssim_4x'] = ssim_4x_normalized\n",
        "        scores[pol][cl]['psnr_4x'] = psnr_4x_normalized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargo\n",
            "Image too small to downscale: data/vh/Tanker/Tanker7074.tif\n",
            "Fishing\n",
            "Tanker\n"
          ]
        }
      ],
      "source": [
        "%timeit\n",
        "def upsample(image, scale_factor, method):\n",
        "    if   method == \"BILINEAR\": method_up = Image.BILINEAR\n",
        "    elif method == \"BICUBIC\":  method_up = Image.BICUBIC\n",
        "    elif method == \"NEAREST\":  method_up = Image.NEAREST\n",
        "    elif method == \"LANCZOS\":  method_up = Image.LANCZOS\n",
        "    else:\n",
        "        print(method, \"not found, using bicubic\")\n",
        "        method_up = Image.BICUBIC\n",
        "\n",
        "    # Resize the image using bicubic interpolation\n",
        "    return image.resize(\n",
        "        (int(image.width * scale_factor), int(image.height * scale_factor)),\n",
        "        method_up\n",
        "    )\n",
        "\n",
        "\n",
        "main_path = \"data/\"\n",
        "storing_data = \"high_data/\"\n",
        "polarizations = [\"vv\", \"vh\"]\n",
        "classes = [\"Cargo\", \"Fishing\", \"Tanker\"]\n",
        "\n",
        "\n",
        "for cl in classes:\n",
        "    print(cl)\n",
        "    vv_path = os.path.join(main_path, polarizations[0], cl)\n",
        "    vh_path = os.path.join(main_path, polarizations[1], cl)\n",
        "    images_list = os.listdir(vv_path)\n",
        "\n",
        "    for i_image in images_list:\n",
        "        vv_image_path = os.path.join(vv_path, i_image)\n",
        "        vh_image_path = os.path.join(vh_path, i_image)\n",
        "\n",
        "        try:\n",
        "            vv_image_hr = Image.open(vv_image_path).convert('RGB')\n",
        "            vh_image_hr = Image.open(vh_image_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error opening image {vv_image_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        original_width, original_height = vv_image_hr.size\n",
        "        \n",
        "        if original_width < 2 or original_height < 2:\n",
        "            print(\"Image too small to downscale:\", image_path)\n",
        "            continue\n",
        "        \n",
        "        for idx, method in enumerate([\"NEAREST\", \"BILINEAR\", \"BICUBIC\", \"LANCZOS\"]):\n",
        "            vv_image_up_2 = upsample(vv_image_hr, scale_factor=2, method=method)\n",
        "            vh_image_up_2 = upsample(vh_image_hr, scale_factor=2, method=method)\n",
        "\n",
        "            hr_path = os.path.join(storing_data, method, \"all_sar\", cl)\n",
        "            \n",
        "            os.makedirs(hr_path, exist_ok=True)\n",
        "            vv_image_up_2.save(os.path.join(hr_path, i_image.replace(\".tif\", \"_vv.tif\")))\n",
        "            vh_image_up_2.save(os.path.join(hr_path, i_image.replace(\".tif\", \"_vh.tif\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Convert the defaultdict to a regular dict\n",
        "scores_dict = {pol: {cl: dict(values) for cl, values in classes.items()} for pol, classes in scores.items()}\n",
        "\n",
        "# Save the scores dictionary to a file\n",
        "with open('super_resolution_scores_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(scores_dict, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the scores dictionary from a file\n",
        "with open('super_resolution_scores_dict.pkl', 'rb') as file:\n",
        "    loaded_scores = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/si-lab/.local/lib/python3.10/site-packages (2.0.2)\n",
            "Requirement already satisfied: openpyxl in /home/si-lab/.local/lib/python3.10/site-packages (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/si-lab/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/si-lab/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /home/si-lab/.local/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
            "Requirement already satisfied: et-xmlfile in /home/si-lab/.local/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vv defaultdict(<class 'dict'>, {'Cargo': {'ssim_2x': [0.8932723552706013, 0.9215749952856858, 0.9271920799547377, 0.928380482745617], 'psnr_2x': [31.08239487082778, 35.17101074863282, 36.54377522157269, 37.33758815764645], 'ssim_4x': [0.8204931359607761, 0.849147708844051, 0.8465192721101246, 0.8406072034697365], 'psnr_4x': [28.31146520837261, 29.567656043748844, 30.083909108052083, 30.340969262681426]}, 'Fishing': {'ssim_2x': [0.6910172661870506, 0.7606539568345323, 0.7810733812949641, 0.7877597122302157], 'psnr_2x': [24.282661870503592, 27.624892086330938, 28.839280575539565, 29.518561151079137], 'ssim_4x': [0.5058107913669063, 0.5506100719424457, 0.5496856115107913, 0.5428654676258994], 'psnr_4x': [21.73410071942447, 22.438057553956835, 22.805899280575538, 22.980647482014387]}, 'Tanker': {'ssim_2x': [0.8726104109589039, 0.9068726575342483, 0.9132987945205476, 0.9145852054794511], 'psnr_2x': [29.686641095890305, 33.80355616438357, 35.2623616438356, 36.11446575342467], 'ssim_4x': [0.7845575890410954, 0.8196238356164408, 0.8157305205479447, 0.8082337534246582], 'psnr_4x': [26.82167671232873, 28.03321643835617, 28.53512876712326, 28.783660273972657]}})\n",
            "Cargo {'ssim_2x': [0.8932723552706013, 0.9215749952856858, 0.9271920799547377, 0.928380482745617], 'psnr_2x': [31.08239487082778, 35.17101074863282, 36.54377522157269, 37.33758815764645], 'ssim_4x': [0.8204931359607761, 0.849147708844051, 0.8465192721101246, 0.8406072034697365], 'psnr_4x': [28.31146520837261, 29.567656043748844, 30.083909108052083, 30.340969262681426]}\n",
            "Fishing {'ssim_2x': [0.6910172661870506, 0.7606539568345323, 0.7810733812949641, 0.7877597122302157], 'psnr_2x': [24.282661870503592, 27.624892086330938, 28.839280575539565, 29.518561151079137], 'ssim_4x': [0.5058107913669063, 0.5506100719424457, 0.5496856115107913, 0.5428654676258994], 'psnr_4x': [21.73410071942447, 22.438057553956835, 22.805899280575538, 22.980647482014387]}\n",
            "Tanker {'ssim_2x': [0.8726104109589039, 0.9068726575342483, 0.9132987945205476, 0.9145852054794511], 'psnr_2x': [29.686641095890305, 33.80355616438357, 35.2623616438356, 36.11446575342467], 'ssim_4x': [0.7845575890410954, 0.8196238356164408, 0.8157305205479447, 0.8082337534246582], 'psnr_4x': [26.82167671232873, 28.03321643835617, 28.53512876712326, 28.783660273972657]}\n",
            "vh defaultdict(<class 'dict'>, {'Cargo': {'ssim_2x': [0.8582358476334164, 0.8879090703375444, 0.896068508391479, 0.8985309258910066], 'psnr_2x': [30.485361116349317, 34.361617952102556, 35.58105034885913, 36.23403733735625], 'ssim_4x': [0.7779533471619836, 0.8080894587969082, 0.8075990571374707, 0.8033680181029622], 'psnr_4x': [27.715934376767862, 29.066790495945718, 29.58934188195361, 29.841352064868985]}, 'Fishing': {'ssim_2x': [0.6711071942446044, 0.7379280575539569, 0.75823309352518, 0.764912230215828], 'psnr_2x': [24.050287769784173, 27.45928057553956, 28.665971223021582, 29.276618705035986], 'ssim_4x': [0.4896302158273379, 0.5351402877697842, 0.5352510791366906, 0.5286877697841726], 'psnr_4x': [21.503956834532367, 22.238705035971225, 22.602374100719427, 22.765683453237408]}, 'Tanker': {'ssim_2x': [0.8382574794520555, 0.8731338082191774, 0.8820693698630144, 0.884644438356166], 'psnr_2x': [29.090339726027402, 33.11189589041098, 34.4402136986302, 35.16109041095886], 'ssim_4x': [0.7445147397260281, 0.7803482739726035, 0.7787012602739737, 0.772989643835617], 'psnr_4x': [26.250536986301352, 27.558312328767098, 28.070975342465758, 28.322926027397298]}})\n",
            "Cargo {'ssim_2x': [0.8582358476334164, 0.8879090703375444, 0.896068508391479, 0.8985309258910066], 'psnr_2x': [30.485361116349317, 34.361617952102556, 35.58105034885913, 36.23403733735625], 'ssim_4x': [0.7779533471619836, 0.8080894587969082, 0.8075990571374707, 0.8033680181029622], 'psnr_4x': [27.715934376767862, 29.066790495945718, 29.58934188195361, 29.841352064868985]}\n",
            "Fishing {'ssim_2x': [0.6711071942446044, 0.7379280575539569, 0.75823309352518, 0.764912230215828], 'psnr_2x': [24.050287769784173, 27.45928057553956, 28.665971223021582, 29.276618705035986], 'ssim_4x': [0.4896302158273379, 0.5351402877697842, 0.5352510791366906, 0.5286877697841726], 'psnr_4x': [21.503956834532367, 22.238705035971225, 22.602374100719427, 22.765683453237408]}\n",
            "Tanker {'ssim_2x': [0.8382574794520555, 0.8731338082191774, 0.8820693698630144, 0.884644438356166], 'psnr_2x': [29.090339726027402, 33.11189589041098, 34.4402136986302, 35.16109041095886], 'ssim_4x': [0.7445147397260281, 0.7803482739726035, 0.7787012602739737, 0.772989643835617], 'psnr_4x': [26.250536986301352, 27.558312328767098, 28.070975342465758, 28.322926027397298]}\n"
          ]
        }
      ],
      "source": [
        "for pol, classes in scores.items():\n",
        "    print(pol, classes)\n",
        "    for cl, metrics in classes.items():\n",
        "        print(cl, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the scores dictionary to a list for Excel\n",
        "data = []\n",
        "\n",
        "for pol, classes in scores.items():\n",
        "    for cl, metrics in classes.items():\n",
        "        # Create a flat dictionary for each class\n",
        "        row = {\n",
        "            'Polarization': pol,\n",
        "            'Class': cl,\n",
        "            'SSIM_2x': metrics.get('ssim_2x', []),\n",
        "            'PSNR_2x': metrics.get('psnr_2x', []),\n",
        "            'SSIM_4x': metrics.get('ssim_4x', []),\n",
        "            'PSNR_4x': metrics.get('psnr_4x', [])\n",
        "        }\n",
        "        # Add the row to the data list\n",
        "        data.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to Excel\n",
        "df.to_excel('super_resolution_scores.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the method labels\n",
        "method_labels = [\"NEAREST\", \"BILINEAR\", \"BICUBIC\", \"LANCZOS\"]\n",
        "\n",
        "# Convert the scores dictionary to a list for Excel\n",
        "data = []\n",
        "\n",
        "for pol, classes in scores.items():\n",
        "    for cl, metrics in classes.items():\n",
        "        # Create a flat dictionary for each class\n",
        "        row = {\n",
        "            'Polarization': pol,\n",
        "            'Class': cl,\n",
        "        }\n",
        "        # Add rounded scores for each method\n",
        "        for idx, method in enumerate(method_labels):\n",
        "            row[f'SSIM_2x_{method}'] = round(metrics.get('ssim_2x', [0])[idx], 4) if idx < len(metrics.get('ssim_2x', [])) else None\n",
        "            row[f'PSNR_2x_{method}'] = round(metrics.get('psnr_2x', [0])[idx], 2) if idx < len(metrics.get('psnr_2x', [])) else None\n",
        "            row[f'SSIM_4x_{method}'] = round(metrics.get('ssim_4x', [0])[idx], 4) if idx < len(metrics.get('ssim_4x', [])) else None\n",
        "            row[f'PSNR_4x_{method}'] = round(metrics.get('psnr_4x', [0])[idx], 2) if idx < len(metrics.get('psnr_4x', [])) else None\n",
        "            \n",
        "        # Add the row to the data list\n",
        "        data.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to Excel\n",
        "df.to_excel('super_resolution_scores.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SR using deep learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of models to iterate through\n",
        "models = {\n",
        "    'EDSR': [edsr(scale=2, pretrained=True), edsr(scale=4, pretrained=True)],\n",
        "    'RCAN': [rcan(scale=2, pretrained=True), rcan(scale=4, pretrained=True)],\n",
        "    'CARN': [carn(scale=2, pretrained=True), carn(scale=4, pretrained=True)]\n",
        "}\n",
        "\n",
        "# Move models to the device once, and freeze them\n",
        "for idx, (model_name, model) in enumerate(models.items()):\n",
        "    model[0].to(device).eval()  # Move 2x model to device\n",
        "    model[1].to(device).eval()  # Move 4x model to device\n",
        "    for param in model[0].parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model[1].parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "main_path = \"data/\"\n",
        "polarizations = [\"vv\", \"vh\"]\n",
        "classes = [\"Cargo\", \"Fishing\", \"Tanker\"]\n",
        "\n",
        "scores = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "for pol in polarizations:\n",
        "    print(pol)\n",
        "    for cl in classes:\n",
        "        print(cl)\n",
        "        p_path = os.path.join(main_path, pol, cl)\n",
        "        images_list = os.listdir(p_path)\n",
        "        t_images = len(images_list)\n",
        "\n",
        "        score_ssim_2x = [0, 0, 0]\n",
        "        score_psnr_2x = [0, 0, 0]\n",
        "        score_ssim_4x = [0, 0, 0]\n",
        "        score_psnr_4x = [0, 0, 0]\n",
        "        for idx, (model_name, model) in enumerate(models.items()):\n",
        "            model[0].to(device)  # Move models to device once, outside of image loop\n",
        "            model[1].to(device)\n",
        "            model[0].eval()\n",
        "            model[1].eval()\n",
        "            for i_image in images_list:\n",
        "                image_path = os.path.join(p_path, i_image)\n",
        "\n",
        "                try:\n",
        "                    image_hr = Image.open(image_path).convert('RGB')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error opening image {image_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "\n",
        "                original_width, original_height = image_hr.size\n",
        "                \n",
        "                if original_width < 2 or original_height < 2:\n",
        "                    print(\"Image too small to downscale:\", image_path)\n",
        "                    continue\n",
        "                \n",
        "                image_lr_2 = image_hr.resize((original_width // 2, original_height // 2), Image.Resampling.LANCZOS)\n",
        "                lr_tensor_2 = ToTensor()(image_lr_2).unsqueeze(0)\n",
        "                image_lr_4 = image_hr.resize((original_width // 4, original_height // 4), Image.Resampling.LANCZOS)\n",
        "                lr_tensor_4 = ToTensor()(image_lr_4).unsqueeze(0)\n",
        "                image_hr_np = np.array(image_hr)\n",
        "                \n",
        "                # Inside the image processing loop\n",
        "                with torch.no_grad():\n",
        "                    sr_tensor2 = model[0](lr_tensor_2.to(device))\n",
        "                    sr_tensor4 = model[1](lr_tensor_4.to(device))\n",
        "\n",
        "                sr_image2 = ToPILImage()(sr_tensor2.squeeze())\n",
        "                sr_image4 = ToPILImage()(sr_tensor4.squeeze())\n",
        "\n",
        "                sr_image2_np = np.array(sr_image2)\n",
        "                sr_image4_np = np.array(sr_image4)\n",
        "\n",
        "                psnr_value_2 = np.round(psnr(image_hr_np, sr_image2_np), 2)\n",
        "                score_psnr_2x[idx] += psnr_value_2\n",
        "\n",
        "                ssim_value_2 = np.round(ssim(image_hr_np, sr_image2_np, win_size=3, channel_axis=-1), 4)\n",
        "                score_ssim_2x[idx] += ssim_value_2\n",
        "\n",
        "                psnr_value_4 = np.round(psnr(image_hr_np, sr_image4_np), 2)\n",
        "                score_psnr_4x[idx] += psnr_value_4\n",
        "\n",
        "                ssim_value_4 = np.round(ssim(image_hr_np, sr_image4_np, win_size=3, channel_axis=-1), 4)\n",
        "                score_ssim_4x[idx] += ssim_value_4\n",
        "        \n",
        "        # Normalize the scores first to avoid redundant np.array() and division operations\n",
        "        ssim_2x_normalized = list(np.array(score_ssim_2x) / t_images)\n",
        "        psnr_2x_normalized = list(np.array(score_psnr_2x) / t_images)\n",
        "        ssim_4x_normalized = list(np.array(score_ssim_4x) / t_images)\n",
        "        psnr_4x_normalized = list(np.array(score_psnr_4x) / t_images)\n",
        "\n",
        "        # Assign the values to the respective dictionary keys\n",
        "        scores[pol][cl]['ssim_2x'] = ssim_2x_normalized\n",
        "        scores[pol][cl]['psnr_2x'] = psnr_2x_normalized\n",
        "        scores[pol][cl]['ssim_4x'] = ssim_4x_normalized\n",
        "        scores[pol][cl]['psnr_4x'] = psnr_4x_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# # import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "# # import cv2\n",
        "# import os\n",
        "# import warnings\n",
        "# from collections import defaultdict\n",
        "# from torchsr.models import edsr, rcan, carn\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "\n",
        "# # List of models to iterate through\n",
        "# models = {\n",
        "#     'EDSR': [edsr(scale=2, pretrained=True), edsr(scale=4, pretrained=True)],\n",
        "#     'RCAN': [rcan(scale=2, pretrained=True), rcan(scale=4, pretrained=True)],\n",
        "#     'CARN': [carn(scale=2, pretrained=True), carn(scale=4, pretrained=True)]\n",
        "# }\n",
        "\n",
        "\n",
        "# # Move models to the device once, and freeze them\n",
        "# for idx, (model_name, model) in enumerate(models.items()):\n",
        "#     model[0].to(device).eval()  # Move 2x model to device\n",
        "#     model[1].to(device).eval()  # Move 4x model to device\n",
        "#     for param in model[0].parameters():\n",
        "#         param.requires_grad = False\n",
        "#     for param in model[1].parameters():\n",
        "#         param.requires_grad = False\n",
        "\n",
        "# main_path = \"data/\"\n",
        "# polarizations = [\"vv\", \"vh\"]\n",
        "# classes = [\"Cargo\", \"Fishing\", \"Tanker\"]\n",
        "\n",
        "# scores = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "# # Custom Dataset for Image Loading\n",
        "# class ImageDataset(Dataset):\n",
        "#     def __init__(self, image_paths):\n",
        "#         self.image_paths = image_paths\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return len(self.image_paths)\n",
        "    \n",
        "#     def __getitem__(self, idx):\n",
        "#         image_path = self.image_paths[idx]\n",
        "#         image = Image.open(image_path).convert('RGB')\n",
        "#         return image_path, image\n",
        "\n",
        "# # Optimized Transformations\n",
        "# to_tensor = ToTensor()\n",
        "# to_pil_image = ToPILImage()\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# for pol in polarizations:\n",
        "#     print(pol)\n",
        "#     for cl in classes:\n",
        "#         print(cl)\n",
        "#         p_path = os.path.join(main_path, pol, cl)\n",
        "#         images_list = os.listdir(p_path)\n",
        "#         t_images = len(images_list)\n",
        "\n",
        "#         # Create DataLoader for efficient image loading\n",
        "#         image_dataset = ImageDataset([os.path.join(p_path, img) for img in images_list])\n",
        "#         image_loader = DataLoader(image_dataset, batch_size=32, num_workers=4, shuffle=False)\n",
        "\n",
        "#         score_ssim_2x = [0, 0, 0]\n",
        "#         score_psnr_2x = [0, 0, 0]\n",
        "#         score_ssim_4x = [0, 0, 0]\n",
        "#         score_psnr_4x = [0, 0, 0]\n",
        "\n",
        "#         for batch in image_loader:\n",
        "#             image_paths, images_hr = batch\n",
        "#             for image_path, image_hr in zip(image_paths, images_hr):\n",
        "#                 original_width, original_height = image_hr.size\n",
        "#                 if original_width < 2 or original_height < 2:\n",
        "#                     print(f\"Image too small to downscale: {image_path}\")\n",
        "#                     continue\n",
        "\n",
        "#                 # Generate low-resolution images (2x and 4x downscaled)\n",
        "#                 image_lr_2 = image_hr.resize((original_width // 2, original_height // 2), Image.LANCZOS)\n",
        "#                 image_lr_4 = image_hr.resize((original_width // 4, original_height // 4), Image.LANCZOS)\n",
        "\n",
        "#                 lr_tensor_2 = to_tensor(image_lr_2).unsqueeze(0).to(device)\n",
        "#                 lr_tensor_4 = to_tensor(image_lr_4).unsqueeze(0).to(device)\n",
        "#                 image_hr_np = np.array(image_hr)\n",
        "\n",
        "#                 for idx, (model_name, model) in enumerate(models.items()):\n",
        "#                     # Super-resolve images with both 2x and 4x models\n",
        "#                     with torch.no_grad():\n",
        "#                         sr_tensor_2 = model[0](lr_tensor_2).squeeze().cpu()  # Move output back to CPU\n",
        "#                         sr_tensor_4 = model[1](lr_tensor_4).squeeze().cpu()\n",
        "\n",
        "#                     # Convert tensor back to images\n",
        "#                     sr_image_2_np = np.array(to_pil_image(sr_tensor_2))\n",
        "#                     sr_image_4_np = np.array(to_pil_image(sr_tensor_4))\n",
        "\n",
        "#                     # Compute PSNR and SSIM scores for both 2x and 4x upscaling\n",
        "#                     psnr_value_2 = np.round(psnr(image_hr_np, sr_image_2_np), 2)\n",
        "#                     ssim_value_2 = np.round(ssim(image_hr_np, sr_image_2_np, win_size=3, channel_axis=-1), 4)\n",
        "\n",
        "#                     score_psnr_2x[idx] += psnr_value_2\n",
        "#                     score_ssim_2x[idx] += ssim_value_2\n",
        "\n",
        "#                     psnr_value_4 = np.round(psnr(image_hr_np, sr_image_4_np), 2)\n",
        "#                     ssim_value_4 = np.round(ssim(image_hr_np, sr_image_4_np, win_size=3, channel_axis=-1), 4)\n",
        "\n",
        "#                     score_psnr_4x[idx] += psnr_value_4\n",
        "#                     score_ssim_4x[idx] += ssim_value_4\n",
        "\n",
        "#         # Normalize the scores after processing all images\n",
        "#         ssim_2x_normalized = list(np.array(score_ssim_2x) / t_images)\n",
        "#         psnr_2x_normalized = list(np.array(score_psnr_2x) / t_images)\n",
        "#         ssim_4x_normalized = list(np.array(score_ssim_4x) / t_images)\n",
        "#         psnr_4x_normalized = list(np.array(score_psnr_4x) / t_images)\n",
        "\n",
        "#         # Assign the values to the respective dictionary keys\n",
        "#         scores[pol][cl]['ssim_2x'] = ssim_2x_normalized\n",
        "#         scores[pol][cl]['psnr_2x'] = psnr_2x_normalized\n",
        "#         scores[pol][cl]['ssim_4x'] = ssim_4x_normalized\n",
        "#         scores[pol][cl]['psnr_4x'] = psnr_4x_normalized\n",
        "\n",
        "# # Convert the defaultdict to a regular dict\n",
        "# scores_dict = {pol: {cl: dict(values) for cl, values in classes.items()} for pol, classes in scores.items()}\n",
        "\n",
        "# # Save the scores dictionary to a file\n",
        "# with open('super_resolution_scores_dict.pkl', 'wb') as file:\n",
        "#     pickle.dump(scores_dict, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the scores dictionary from a file\n",
        "with open('super_resolution_scores_dict.pkl', 'rb') as file:\n",
        "    loaded_scores = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the method labels\n",
        "method_labels = [\"EDSR\", \"RCAN\", \"CARN\"]\n",
        "\n",
        "# Convert the scores dictionary to a list for Excel\n",
        "data = []\n",
        "\n",
        "for pol, classes in loaded_scores.items():\n",
        "    for cl, metrics in classes.items():\n",
        "        # Create a flat dictionary for each class\n",
        "        row = {\n",
        "            'Polarization': pol,\n",
        "            'Class': cl,\n",
        "        }\n",
        "        # Add rounded scores for each method\n",
        "        for idx, method in enumerate(method_labels):\n",
        "            row[f'SSIM_2x_{method}'] = round(metrics.get('ssim_2x', [0])[idx], 4) if idx < len(metrics.get('ssim_2x', [])) else None\n",
        "            row[f'PSNR_2x_{method}'] = round(metrics.get('psnr_2x', [0])[idx], 2) if idx < len(metrics.get('psnr_2x', [])) else None\n",
        "            row[f'SSIM_4x_{method}'] = round(metrics.get('ssim_4x', [0])[idx], 4) if idx < len(metrics.get('ssim_4x', [])) else None\n",
        "            row[f'PSNR_4x_{method}'] = round(metrics.get('psnr_4x', [0])[idx], 2) if idx < len(metrics.get('psnr_4x', [])) else None\n",
        "            \n",
        "        # Add the row to the data list\n",
        "        data.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to Excel\n",
        "df.to_excel('super_resolution_scores_dl.xlsx', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "arqesp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
